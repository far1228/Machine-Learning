# -*- coding: utf-8 -*-
"""Pendekatan Fitur Klasik

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cVCzW9hLp7F58WW7a0K8WqE7c67-4vbn

#Pendekatan Fitur Klasik

##Demographic Dataset
"""

# =========================================================
# LOAD DATASET HASIL QI LABELING
# =========================================================
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer

# Ganti path sesuai file kamu
PATH = "/content/demographics_with_qi_labels.csv"
df = pd.read_csv(PATH)

print(f"Jumlah data: {len(df)} baris\n")
print("Kolom tersedia:", df.columns.tolist())

# Pastikan kolom clean_text & label ada
assert "clean_text" in df.columns, "Kolom 'clean_text' tidak ditemukan!"
assert "label" in df.columns, "Kolom 'label' tidak ditemukan ‚Äî pastikan hasil QI sudah dijalankan!"

# Bersihkan data kosong
df["clean_text"] = df["clean_text"].fillna("").astype(str)
display(df.head(5))

# =========================================================
# Demographic ‚Äî SPLIT DATA
# =========================================================
X = df["clean_text"]
y = df["label"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print("Data latih:", len(X_train))
print("Data uji  :", len(X_test))

"""###BoW"""

# =========================================================
# Ekstraksi fitur Bag-of-Words (BoW)
# Tujuan:
# - Mengubah teks terproses menjadi representasi vektor frekuensi.
# - Digunakan untuk model klasifikasi klasik.
# =========================================================

import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer

df_demo = pd.read_csv("/content/demographics_with_qi_labels.csv")

vectorizer_bow = CountVectorizer(
    ngram_range=(1,1),
    min_df=2,
    max_df=0.95,
    token_pattern=r"(?u)\b[a-zA-Z][a-zA-Z]+\b"
)

X_bow = vectorizer_bow.fit_transform(df_demo["clean_text"])
bow_df = pd.DataFrame(X_bow.toarray(), columns=vectorizer_bow.get_feature_names_out())

bow_df.to_csv("/content/BOW_demographics.csv", index=False)
print("Ekstraksi BoW selesai.")
bow_df.head()

"""###TF-IDF"""

# =========================================================
# Ekstraksi fitur TF-IDF
# Tujuan:
# - Menghasilkan representasi berbobot yang mengutamakan kata bermakna.
# - Mengurangi pengaruh kata umum (non-informatif).
# =========================================================

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer

df_demo = pd.read_csv("/content/demographics_with_qi_labels.csv")

vectorizer_tfidf = TfidfVectorizer(
    ngram_range=(1,1),
    min_df=2,
    max_df=0.95,
    token_pattern=r"(?u)\b[a-zA-Z][a-zA-Z]+\b"
)

X_tfidf = vectorizer_tfidf.fit_transform(df_demo["clean_text"])
tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=vectorizer_tfidf.get_feature_names_out())

tfidf_df.to_csv("/content/TFIDF_demographics.csv", index=False)
print("Ekstraksi TF-IDF selesai.")
tfidf_df.head()

"""###N-Gram"""

# =========================================================
# Ekstraksi fitur Bigram
# Tujuan:
# - Menangkap konteks dua kata berurutan.
# - Berguna untuk memodelkan hubungan antar-token.
# =========================================================

import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer

df_demo = pd.read_csv("/content/demographics_with_qi_labels.csv")

vectorizer_bigram = CountVectorizer(
    ngram_range=(2,2),
    min_df=2,
    max_df=0.95,
    token_pattern=r"(?u)\b[a-zA-Z][a-zA-Z]+\b"
)

X_bigram = vectorizer_bigram.fit_transform(df_demo["clean_text"])
bigram_df = pd.DataFrame(X_bigram.toarray(), columns=vectorizer_bigram.get_feature_names_out())

bigram_df.to_csv("/content/BIGRAM_demographics.csv", index=False)
print("Ekstraksi Bigram selesai.")
bigram_df.head()

"""#Pendekatan Fitur Klasik

##Clinical Dataset
"""

# =========================================================
# CLINICAL ‚Äî LOAD DATASET HASIL QI LABELING
# =========================================================
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer

PATH = "/content/ClinicalData_with_qi_labels.csv"
df = pd.read_csv(PATH)

print(f"Jumlah data: {len(df)} baris\n")
print("Kolom tersedia:", df.columns.tolist())

assert "clean_text" in df.columns, "Kolom 'clean_text' tidak ditemukan!"
assert "label" in df.columns, "Kolom 'label' tidak ditemukan ‚Äî pastikan hasil QI sudah dijalankan!"

df["clean_text"] = df["clean_text"].fillna("").astype(str)
display(df.head(5))


# =========================================================
# CLINICAL ‚Äî SPLIT DATA
# =========================================================
X = df["clean_text"]
y = df["label"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print("Data latih:", len(X_train))
print("Data uji  :", len(X_test))

"""###BoW"""

# =========================================================
# PENDEKATAN FITUR ‚Äî BAG OF WORDS (CLEANED)
# =========================================================
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer

# === 1. Load dataset ===
df = pd.read_csv("/content/ClinicalData_with_qi_labels.csv")
print(f"Jumlah data: {len(df)} baris\n")
print("Kolom tersedia:", df.columns.tolist())

# === 2. Vectorizer dengan parameter pembersihan ===
bow_vectorizer = CountVectorizer(
    ngram_range=(1, 1),          # hanya unigram
    min_df=2,                    # minimal muncul di 2 dokumen
    max_df=0.95,                 # maksimal muncul di 95% dokumen
    token_pattern=r"(?u)\b[a-zA-Z][a-zA-Z]+\b"  # hanya ambil token huruf (hindari angka seperti 19, 40, 99)
)

X_bow = bow_vectorizer.fit_transform(df["clean_text"])

# === 3. Konversi ke DataFrame ===
bow_df = pd.DataFrame(
    X_bow.toarray(),
    columns=bow_vectorizer.get_feature_names_out()
)

# === 4. Info hasil ===
print(f"Bentuk matriks BoW: {X_bow.shape}")
print("Jumlah fitur:", X_bow.shape[1])
print("Contoh fitur:", bow_vectorizer.get_feature_names_out()[:15])

# === 5. Simpan hasil ===
out_path = "/content/BOW_ClinicalData_cleaned.csv"
bow_df.to_csv(out_path, index=False, encoding="utf-8-sig")
print(f"\n‚úÖ BoW selesai!\nüìÅ Disimpan di: {out_path}")
display(bow_df.head(5))

"""###TF_IDF"""

# =========================================================
# PENDEKATAN FITUR ‚Äî TF-IDF DENGAN FILTER TOKEN
# =========================================================
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer

# === 1. Load dataset ===
df = pd.read_csv("/content/ClinicalData_with_qi_labels.csv")
print(f"Jumlah data: {len(df)} baris\n")
print("Kolom tersedia:", df.columns.tolist())

# === 2. Vectorizer dengan filter token ===
tfidf_vectorizer = TfidfVectorizer(
    ngram_range=(1, 1),          # unigram
    min_df=2,                    # abaikan kata yang muncul <2 dokumen
    max_df=0.95,                 # abaikan kata terlalu umum (>95% dokumen)
    token_pattern=r"(?u)\b[a-zA-Z][a-zA-Z]+\b"  # hanya token huruf (hindari angka seperti '1010')
)

X_tfidf = tfidf_vectorizer.fit_transform(df["clean_text"])

# === 3. Konversi ke DataFrame ===
tfidf_df = pd.DataFrame(
    X_tfidf.toarray(),
    columns=tfidf_vectorizer.get_feature_names_out()
)

# === 4. Info hasil ===
print(f"Bentuk matriks TF-IDF: {X_tfidf.shape}")
print("Jumlah fitur:", X_tfidf.shape[1])
print("Contoh fitur:", tfidf_vectorizer.get_feature_names_out()[:15])

# === 5. Simpan hasil ===
out_path = "/content/TFIDF_ClinicalData.csv"
tfidf_df.to_csv(out_path, index=False, encoding="utf-8-sig")
print(f"\n‚úÖ TF-IDF selesai!\nüìÅ Disimpan di: {out_path}")
display(tfidf_df.head(5))

"""###N-Gram"""

# =========================================================
# PENDEKATAN FITUR ‚Äî N-GRAM (BIGRAM, CLEANED)
# =========================================================
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer

# === 1. Load dataset ===
df = pd.read_csv("/content/ClinicalData_with_qi_labels.csv")
print(f"Jumlah data: {len(df)} baris\n")
print("Kolom tersedia:", df.columns.tolist())

# === 2. Vectorizer dengan filter token ===
ngram_vectorizer = CountVectorizer(
    ngram_range=(2, 2),          # ambil pasangan kata (bigram)
    min_df=2,                    # minimal muncul di 2 dokumen
    max_df=0.95,                 # maksimal muncul di 95% dokumen
    token_pattern=r"(?u)\b[a-zA-Z][a-zA-Z]+\b"  # hanya ambil kata huruf (hindari angka)
)

X_ngram = ngram_vectorizer.fit_transform(df["clean_text"])

# === 3. Konversi ke DataFrame ===
ngram_df = pd.DataFrame(
    X_ngram.toarray(),
    columns=ngram_vectorizer.get_feature_names_out()
)

# === 4. Info hasil ===
print(f"Bentuk matriks N-gram (Bigram): {X_ngram.shape}")
print("Jumlah fitur:", X_ngram.shape[1])
print("Contoh fitur:", ngram_vectorizer.get_feature_names_out()[:15])

# === 5. Simpan hasil ===
out_path = "/content/NGRAM_ClinicalData_cleaned.csv"
ngram_df.to_csv(out_path, index=False, encoding="utf-8-sig")
print(f"\n‚úÖ N-gram (Bigram) selesai!\nüìÅ Disimpan di: {out_path}")
display(ngram_df.head(5))