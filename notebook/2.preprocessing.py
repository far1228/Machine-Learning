# -*- coding: utf-8 -*-
"""Preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Cvg_HmQd8KsVbTxBphkmZDUUTxxgxE0j

#Preprocessing

##Demographic Dataset
"""

# =========================================================
# Preprocessing teks demografis
# Tujuan:
# - Membersihkan teks dari noise linguistik.
# - Menormalkan token hasil anonimisasi.
# - Menghilangkan stopword untuk optimasi pemodelan.
# =========================================================

import re
import nltk
from nltk.corpus import stopwords
import pandas as pd

nltk.download("stopwords")

# Memuat hasil anonimisasi
df_demo_pre = pd.read_csv("/content/demographics_anoon.csv", header=None, names=["text"])

# Daftar stopword (ID, EN, dan tambahan domain)
stopwords_id = set(stopwords.words("indonesian"))
stopwords_en = set(stopwords.words("english"))
custom_stop = {
    "yang","dan","di","ke","dari","pada","untuk","dengan",
    "adalah","seorang","dalam","oleh","itu","ini","hari",
    "bulan","pukul","sekitar","tersebut"
}

stop_words = stopwords_id.union(stopwords_en).union(custom_stop)

# Fungsi utama preprocessing
def preprocess_serialized_text(text: str) -> str:
    """
    Membersihkan teks:
    - Lowercase, normalisasi unicode.
    - Mengganti token anonim menjadi token generik.
    - Menghapus simbol non-alfanumerik.
    - Menghapus stopword dan angka non-informatif.
    """
    if pd.isna(text):
        return ""

    text = text.lower()
    text = text.replace("–", "-").replace("—", "-")
    text = re.sub(r'patient_[a-z0-9]+', 'patienttoken', text)
    text = re.sub(r'hospital_[a-z0-9]+', 'hospitaltoken', text)
    text = re.sub(r'[^a-z0-9\s\-]', ' ', text)
    text = re.sub(r'\s+', ' ', text).strip()

    tokens = [
        w for w in text.split()
        if w not in stop_words and not re.match(r'^\d+$', w)
    ]

    clean_text = " ".join(tokens)
    clean_text = re.sub(r'(\d{1,3})-(\d{1,3})', r'\1-\2', clean_text)

    return clean_text

df_demo_pre["clean_text"] = df_demo_pre["text"].astype(str).apply(preprocess_serialized_text)

out_path_demo_pre = "/content/demographics_preprocessed.csv"
df_demo_pre[["clean_text"]].to_csv(out_path_demo_pre, index=False, encoding="utf-8-sig")

print(f"Preprocessing selesai. Hasil disimpan di: {out_path_demo_pre}")
print(df_demo_pre["clean_text"].head(5))

"""#Preprocessing

##CLinical Dataset
"""

# =========================================================
# Preprocessing teks teranonim
# Sumber  : ClinicalData_anonymized.csv
# Output  : ClinicalData_preprocessed.csv (kolom clean_text)
# =========================================================

"""##Preprocessing"""

import re
import pandas as pd
import nltk
from nltk.corpus import stopwords

# === 1. Download stopword ===
nltk.download("stopwords")

# === 2. Baca dataset hasil anonimisasi ===
df = pd.read_csv("/content/ClinicalData_anonymized.csv")
print(f"Jumlah data: {len(df)} baris\n")

# Pastikan kolom teks benar
text_column = "text_anonymized"
print("Kolom:", df.columns.tolist())

# === 3. Siapkan stopword ===
stopwords_id = set(stopwords.words("indonesian"))
stopwords_en = set(stopwords.words("english"))
custom_stop = {
    "yang", "dan", "di", "ke", "dari", "pada", "untuk", "dengan", "adalah",
    "seorang", "dalam", "oleh", "itu", "ini", "hari", "bulan", "pukul",
    "sekitar", "tersebut", "dapat", "tanpa", "selama", "tidak", "akan",
    "ialah", "adalah", "yaitu", "yakni", "serta", "juga"
}
# “tahun” tidak dihapus agar konteks umur tetap
stop_words = stopwords_id.union(stopwords_en).union(custom_stop)

# === 4. Fungsi preprocessing ===
def preprocess_clinical_text(text):
    if pd.isna(text):
        return ""

    # 1. Lowercase teks
    text = text.lower()

    # 2. Normalisasi tanda hubung unicode
    text = text.replace("–", "-").replace("—", "-")

    # 3. Tokenisasi untuk placeholder anonimisasi
    text = re.sub(r'patient_[a-z0-9]+', 'patienttoken', text)
    text = re.sub(r'hospital_[a-z0-9]+', 'hospitaltoken', text)
    text = re.sub(r'<angka_tersembunyi>', 'numtoken', text)

    # 4. Bersihkan simbol non-alfanumerik
    text = re.sub(r'[^a-z0-9\s\-]', ' ', text)

    # 5. Hapus stopword namun pertahankan angka penting
    tokens = []
    for w in text.split():
        if w not in stop_words and not re.match(r'^\d+$', w):
            tokens.append(w)

    text = " ".join(tokens)

    # 6. Gabungkan format umur seperti "60-79"
    text = re.sub(r'(\d{1,3})-(\d{1,3})', r'\1-\2', text)

    # 7. Hapus unit standar yang tidak relevan
    text = re.sub(r'\b(cm|kg|ml|menit)\b', '', text)

    # 8. Perbaiki spasi ganda
    text = re.sub(r'\s+', ' ', text).strip()

    return text

# === 5. Terapkan ke seluruh dataset ===
df["clean_text"] = df[text_column].astype(str).apply(preprocess_clinical_text)

# === 6. Simpan hasil ===
out_path = "/content/ClinicalData_preprocessed.csv"
df[["clean_text"]].to_csv(out_path, index=False, encoding="utf-8-sig")

print(f"Preprocessing selesai! Hasil disimpan di: {out_path}")
print("\nContoh hasil:")
print(df["clean_text"].head(3))